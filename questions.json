{
  "questions": [
    {
      "questionNumber": 1,
      "question": "true or false: Alan Turing coined the term 'Artificial Intelligence' at the 1956 Dartmouth Conference.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "While Alan Turing was a foundational figure in AI and computing, the term itself was coined by someone else at this specific event.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "It was John McCarthy who coined the term 'Artificial Intelligence' for the 1956 Dartmouth Conference, which is considered the birth of AI as a field.",
          "isCorrect": true
        }
      ],
      "hint": "Think about the key figures associated with the official naming of the AI research field."
    },
    {
      "questionNumber": 2,
      "question": "An AI system designed to help doctors diagnose diseases more accurately primarily demonstrates which ethical principle?",
      "answerOptions": [
        {
          "text": "Justice",
          "rationale": "Justice relates to fairness and non-discrimination. While important in healthcare AI, the primary goal here is promoting positive health outcomes.",
          "isCorrect": false
        },
        {
          "text": "Beneficence",
          "rationale": "Beneficence is the principle of promoting well-being and doing good. An AI that improves medical diagnoses directly serves this purpose.",
          "isCorrect": true
        },
        {
          "text": "Autonomy",
          "rationale": "Autonomy concerns preserving human control and choice. While a doctor retains autonomy, the AI's core purpose in this case is to provide a benefit.",
          "isCorrect": false
        },
        {
          "text": "Explicability",
          "rationale": "Explicability (transparency and accountability) is crucial for trusting the AI's diagnosis, but the fundamental goal of the tool is to help the patient.",
          "isCorrect": false
        }
      ],
      "hint": "Which principle focuses on acting for the good and well-being of others?"
    },
    {
      "questionNumber": 3,
      "question": "The creation of highly realistic but fake videos to spread misinformation is an example of:",
      "answerOptions": [
        {
          "text": "Bluewashing",
          "rationale": "Bluewashing refers to organizations claiming ethical commitment without meaningful action, not the creation of fake media.",
          "isCorrect": false
        },
        {
          "text": "Phishing",
          "rationale": "Phishing is a type of cybercrime that involves tricking individuals into revealing sensitive information, not creating synthetic videos.",
          "isCorrect": false
        },
        {
          "text": "Deepfakes",
          "rationale": "This term specifically refers to synthetic media generated by AI where a person in an existing image or video is replaced with someone else's likeness.",
          "isCorrect": true
        },
        {
          "text": "Robotic Process Automation",
          "rationale": "RPA involves automating repetitive tasks using software robots, which is unrelated to generating manipulative video content.",
          "isCorrect": false
        }
      ],
      "hint": "This technology uses deep learning to synthesize media, often for malicious purposes."
    },
    {
      "questionNumber": 4,
      "question": "Which branch of AI allows systems to learn from data and experience without being explicitly programmed?",
      "answerOptions": [
        {
          "text": "Symbolic AI",
          "rationale": "Symbolic AI, or GOFAI, relies on explicit rules and logic programmed by humans, rather than learning from data.",
          "isCorrect": false
        },
        {
          "text": "Machine Learning",
          "rationale": "This is the core definition of machine learning, where algorithms are trained on data to find patterns and make predictions.",
          "isCorrect": true
        },
        {
          "text": "Robotics",
          "rationale": "Robotics deals with the design and control of machines that interact with the physical world; it often uses machine learning but is not the learning process itself.",
          "isCorrect": false
        },
        {
          "text": "Computer Vision",
          "rationale": "Computer vision is a field of AI that enables computers to interpret and understand visual information; it is an application area that uses machine learning.",
          "isCorrect": false
        }
      ],
      "hint": "This is a fundamental subset of AI that includes supervised, unsupervised, and reinforcement types of learning."
    },
    {
      "questionNumber": 5,
      "question": "true or false: The ethical principle of 'Nonmaleficence' means that AI should actively promote human well-being.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "This describes the principle of Beneficence. Nonmaleficence has a different, though related, focus.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "Nonmaleficence means 'do no harm.' It is about avoiding and preventing harmful outcomes, which is distinct from actively promoting good (Beneficence).",
          "isCorrect": true
        }
      ],
      "hint": "Consider the distinction between actively doing good and passively avoiding bad outcomes."
    },
    {
      "questionNumber": 6,
      "question": "A hiring algorithm that systematically favors candidates from one demographic over another, even if unintentional, is exhibiting what major ethical problem?",
      "answerOptions": [
        {
          "text": "Opacity",
          "rationale": "Opacity refers to the 'black box' nature of an AI, making it hard to understand its reasoning. While related, the direct problem described is the unfair outcome.",
          "isCorrect": false
        },
        {
          "text": "Bias",
          "rationale": "Algorithmic bias occurs when a system produces systematically prejudiced results, often because it was trained on biased historical data.",
          "isCorrect": true
        },
        {
          "text": "Lack of Autonomy",
          "rationale": "This principle relates to human control over AI. The issue here is about fairness in the AI's own decision-making process.",
          "isCorrect": false
        },
        {
          "text": "Misguided Evidence",
          "rationale": "This epistemic concern is a cause of bias, but 'bias' is the term for the resulting unfair systematic outcome.",
          "isCorrect": false
        }
      ],
      "hint": "This problem often arises from skewed or unrepresentative training data."
    },
    {
      "questionNumber": 7,
      "question": "The concept of 'Green AI' is primarily concerned with:",
      "answerOptions": [
        {
          "text": "Using AI to monitor and protect natural ecosystems.",
          "rationale": "While a valid application of AI for environmental good, this is not the primary definition of 'Green AI.'",
          "isCorrect": false
        },
        {
          "text": "Maximizing the accuracy and performance of AI models regardless of cost.",
          "rationale": "This approach is often what 'Green AI' critiques, as it can lead to massive computational and energy costs.",
          "isCorrect": false
        },
        {
          "text": "Reducing the energy consumption and carbon footprint of AI research and applications.",
          "rationale": "Green AI focuses on improving the computational efficiency of AI to make it more environmentally sustainable.",
          "isCorrect": true
        },
        {
          "text": "Developing AI systems that can create environmentally-themed art.",
          "rationale": "This is a creative application of generative AI but does not capture the core focus of the Green AI movement.",
          "isCorrect": false
        }
      ],
      "hint": "This field of study focuses on the computational and environmental costs associated with AI itself."
    },
    {
      "questionNumber": 8,
      "question": "Which of these is the best example of 'Democratized AI'?",
      "answerOptions": [
        {
          "text": "An advanced AI system used exclusively by a government for national security.",
          "rationale": "This represents a specialized, high-stakes use of AI, not one that is widely accessible.",
          "isCorrect": false
        },
        {
          "text": "An AI model that requires a supercomputer and a team of PhDs to operate.",
          "rationale": "This is the opposite of democratization, as it restricts access to those with significant resources.",
          "isCorrect": false
        },
        {
          "text": "A no-code/low-code online platform that allows anyone to build a simple AI chatbot.",
          "rationale": "Democratization aims to make AI tools accessible and usable for people without deep technical expertise.",
          "isCorrect": true
        },
        {
          "text": "An AI algorithm that decides on stock market trades in milliseconds.",
          "rationale": "This is a highly specialized application and does not reflect broad accessibility for the general public.",
          "isCorrect": false
        }
      ],
      "hint": "This trend is about making AI tools more accessible and inclusive for everyone."
    },
    {
      "questionNumber": 9,
      "question": "The ethical principle of 'Explicability' in AI combines which two key concepts?",
      "answerOptions": [
        {
          "text": "Privacy and Security",
          "rationale": "While privacy and security are crucial ethical concerns, they are distinct from the principle of making an AI's operations understandable.",
          "isCorrect": false
        },
        {
          "text": "Beneficence and Nonmaleficence",
          "rationale": "These principles concern the positive and negative impacts of AI (doing good and avoiding harm), whereas explicability is about how we can understand and govern those impacts.",
          "isCorrect": false
        },
        {
          "text": "Intelligibility and Accountability",
          "rationale": "Explicability requires that an AI's decision-making process is understandable (intelligible) and that someone can be held responsible for its outcomes (accountability).",
          "isCorrect": true
        },
        {
          "text": "Autonomy and Justice",
          "rationale": "Autonomy relates to human control, and justice relates to fairness. Explicability is the principle that enables the proper implementation of both.",
          "isCorrect": false
        }
      ],
      "hint": "This principle is about both understanding how an AI works and being able to assign responsibility for its actions."
    },
    {
      "questionNumber": 10,
      "question": "true or false: An autonomous vehicle that operates without human intervention is considered an example of Artificial General Intelligence (AGI).",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "Autonomous vehicles are highly sophisticated but are designed for the specific task of driving. They cannot perform general intellectual tasks like a human can.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "This is an example of Narrow AI. It performs a very complex but specific task. AGI is a hypothetical form of AI with human-like general cognitive abilities, which does not yet exist.",
          "isCorrect": true
        }
      ],
      "hint": "Consider the difference between a system that is an expert in one task versus one that can learn and perform any task."
    },
    {
      "questionNumber": 11,
      "question": "Digital governance, digital regulation, and digital ethics are distinct concepts. Which one refers to the frameworks and processes organizations use to manage their digital operations and align them with strategic goals?",
      "answerOptions": [
        {
          "text": "Digital Ethics",
          "rationale": "Digital ethics refers to the moral principles and values that guide the use of technology, not the management frameworks.",
          "isCorrect": false
        },
        {
          "text": "Digital Regulation",
          "rationale": "Digital regulation involves the creation and enforcement of legally binding laws and policies.",
          "isCorrect": false
        },
        {
          "text": "Digital Governance",
          "rationale": "This correctly describes digital governance, which encompasses the internal policies, oversight, and management structures for an organization's digital activities.",
          "isCorrect": true
        },
        {
          "text": "Digital Autonomy",
          "rationale": "Digital autonomy is not one of the three core concepts in this triad; it relates to individual control in the digital sphere.",
          "isCorrect": false
        }
      ],
      "hint": "Which term is most associated with internal management, oversight, and strategic alignment within an organization?"
    },
    {
      "questionNumber": 12,
      "question": "What is the primary function of Generative AI?",
      "answerOptions": [
        {
          "text": "To classify existing data into predefined categories.",
          "rationale": "This describes a primary function of discriminative AI models used in tasks like image recognition, not generative models.",
          "isCorrect": false
        },
        {
          "text": "To create new and original content, such as text, images, or music.",
          "rationale": "Generative models are defined by their ability to produce novel content based on patterns learned from training data.",
          "isCorrect": true
        },
        {
          "text": "To control physical robots in a manufacturing setting.",
          "rationale": "While a generative model could potentially design a part for a robot to build, its primary function is content creation, not physical control.",
          "isCorrect": false
        },
        {
          "text": "To find the optimal solution to a logical problem through rules.",
          "rationale": "This is more characteristic of Symbolic AI or optimization algorithms, not the creative function of generative models.",
          "isCorrect": false
        }
      ],
      "hint": "Think about what models like GPT-3 and DALL-E are designed to do."
    },
    {
      "questionNumber": 13,
      "question": "The ethical concern of 'Inscrutable Evidence' in an AI system refers to:",
      "answerOptions": [
        {
          "text": "The data used by the algorithm is insufficient to make a reliable decision.",
          "rationale": "This describes the concern of 'Inconclusive Evidence', not inscrutable evidence.",
          "isCorrect": false
        },
        {
          "text": "The data or evidence used by the algorithm is difficult to understand or interpret.",
          "rationale": "This is the correct definition. The evidence might be ambiguous or mysterious, making the AI's reasoning opaque.",
          "isCorrect": true
        },
        {
          "text": "The algorithm produces an outcome that is unjust or biased against a certain group.",
          "rationale": "This describes the normative concern of 'Unfair Outcomes'.",
          "isCorrect": false
        },
        {
          "text": "The data used by the algorithm is flawed or biased, leading to incorrect decisions.",
          "rationale": "This describes the concern of 'Misguided Evidence'.",
          "isCorrect": false
        }
      ],
      "hint": "This epistemic concern is related to the clarity and interpretability of the data itself."
    },
    {
      "questionNumber": 14,
      "question": "true or false: According to the provided materials, one of the ethical opportunities of using AI to combat climate change is to optimize resource management, such as energy and water usage.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The documents highlight that AI can deliver greener and more effective solutions by improving and optimizing energy generation and use, such as in electrical grid management.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "The materials explicitly state that AI presents ethical opportunities to improve resource management and energy efficiency as part of climate action.",
          "isCorrect": false
        }
      ],
      "hint": "Consider how AI's analytical power could be applied to complex systems like a nation's power grid."
    },
    {
      "questionNumber": 15,
      "question": "Which of the following is NOT a key component of human intelligence as described in the course materials?",
      "answerOptions": [
        {
          "text": "Emotional Intelligence",
          "rationale": "The ability to understand and manage emotions is listed as a key component that distinguishes human intelligence.",
          "isCorrect": false
        },
        {
          "text": "Algorithmic Processing Speed",
          "rationale": "While humans process information, high-speed algorithmic calculation is a strength of computers, not a defining component of human intelligence itself.",
          "isCorrect": true
        },
        {
          "text": "Creativity",
          "rationale": "The capacity to generate new and original ideas is highlighted as a fundamental aspect of human intelligence.",
          "isCorrect": false
        },
        {
          "text": "Social Intelligence",
          "rationale": "The ability to navigate social environments and understand social dynamics is identified as a key part of human intelligence.",
          "isCorrect": false
        }
      ],
      "hint": "Focus on the cognitive and emotional abilities that are uniquely human, rather than computational strengths."
    },
    {
      "questionNumber": 16,
      "question": "Who created the first known artificial automatic self-regulatory system, the clepsydra (water clock), around 250 BC?",
      "answerOptions": [
        {
          "text": "Alan Turing",
          "rationale": "Alan Turing was a 20th-century pioneer of computing, not an ancient inventor.",
          "isCorrect": false
        },
        {
          "text": "Leonardo da Vinci",
          "rationale": "Leonardo da Vinci designed mechanical devices in the Middle Ages, but the water clock predates him significantly.",
          "isCorrect": false
        },
        {
          "text": "Ctesibius",
          "rationale": "Ctesibius of Alexandria, a Greek inventor, is credited with developing the water clock, an early example of an automated regulatory device.",
          "isCorrect": true
        },
        {
          "text": "John McCarthy",
          "rationale": "John McCarthy is a modern figure who coined the term 'Artificial Intelligence' in 1956.",
          "isCorrect": false
        }
      ],
      "hint": "This inventor was from ancient Greece and is known for his work in pneumatics and hydraulics."
    },
    {
      "questionNumber": 17,
      "question": "Legally binding rules that must be followed, such as the GDPR, fall under the category of:",
      "answerOptions": [
        {
          "text": "Soft Ethics",
          "rationale": "Soft ethics refers to non-binding guidelines and principles, not enforceable laws.",
          "isCorrect": false
        },
        {
          "text": "Digital Governance",
          "rationale": "Digital governance refers to internal management frameworks, not external, legally-binding regulations.",
          "isCorrect": false
        },
        {
          "text": "Hard Ethics",
          "rationale": "Hard ethics are defined as strict, enforced precepts that are typically included in laws and regulations with specific consequences for infractions.",
          "isCorrect": true
        },
        {
          "text": "Normative Ethics",
          "rationale": "Normative ethics is a branch of moral philosophy concerned with what is morally right and wrong, which informs laws but is not the same as the laws themselves.",
          "isCorrect": false
        }
      ],
      "hint": "This term refers to strict, enforceable rules with legal consequences."
    },
    {
      "questionNumber": 18,
      "question": "In the context of AI crime, the 'Perpetration-by-Another Model' for assigning liability considers the AI system to be:",
      "answerOptions": [
        {
          "text": "Directly liable and possessing a criminal mind.",
          "rationale": "This describes the 'Direct Liability Model', which is currently unfeasible as AIs lack legal personality.",
          "isCorrect": false
        },
        {
          "text": "A negligent party that failed to prevent harm.",
          "rationale": "This is more aligned with the 'Natural-Probable-Consequence Model'.",
          "isCorrect": false
        },
        {
          "text": "An instrument of crime, with the human orchestrator being the true perpetrator.",
          "rationale": "This model correctly views the AI as a tool used by a human, to whom the actual criminal intent is ascribed.",
          "isCorrect": true
        },
        {
          "text": "A military commander who failed to prevent a crime.",
          "rationale": "This describes the 'Command Responsibility Model', which is specific to military contexts.",
          "isCorrect": false
        }
      ],
      "hint": "In this liability model, the AI is seen as a tool or weapon used by a person."
    },
    {
      "questionNumber": 19,
      "question": "Which of the following is NOT one of the seven essential factors for successful AI for Social Good (AI4SG)?",
      "answerOptions": [
        {
          "text": "Falsifiability and incremental deployment",
          "rationale": "This is listed as a key factor, ensuring systems can be tested and improved reliably.",
          "isCorrect": false
        },
        {
          "text": "Maximizing profit and market share",
          "rationale": "AI4SG is focused on social and environmental well-being, not commercial objectives, making this the correct answer.",
          "isCorrect": true
        },
        {
          "text": "Privacy protection and data subject consent",
          "rationale": "This is a crucial factor, aligning with the ethical principles of nonmaleficence and autonomy.",
          "isCorrect": false
        },
        {
          "text": "Situational fairness",
          "rationale": "This factor, which involves removing irrelevant variables from datasets to support fairness, is explicitly listed.",
          "isCorrect": false
        }
      ],
      "hint": "The principles of AI4SG focus on ethical and beneficial outcomes for society and the environment, not commercial success."
    },
    {
      "questionNumber": 20,
      "question": "The concept that the development of AI could lead to a 'terminator future' is most closely associated with the emergence of:",
      "answerOptions": [
        {
          "text": "Narrow AI",
          "rationale": "Narrow AI is task-specific and does not pose the kind of existential risk implied by this scenario.",
          "isCorrect": false
        },
        {
          "text": "Artificial General Intelligence (AGI)",
          "rationale": "AGI, or a hypothetical machine with human-level general intelligence, is what captures the imagination of dystopian sci-fi and raises concerns about uncontrollable superintelligence.",
          "isCorrect": true
        },
        {
          "text": "Explainable AI (XAI)",
          "rationale": "XAI is a field focused on making AI more transparent and is seen as a way to mitigate risks, not create them.",
          "isCorrect": false
        },
        {
          "text": "Conversational AI",
          "rationale": "Conversational AI like chatbots, while advanced, does not possess the general intelligence that would lead to such scenarios.",
          "isCorrect": false
        }
      ],
      "hint": "This hypothetical type of AI would have cognitive abilities comparable to a human."
    },
    {
      "questionNumber": 21,
      "question": "true or false: The epistemological opportunity presented by AI for climate change involves its ability to process vast amounts of data to improve climate models and forecasts.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The materials state that the epistemological impact of AI involves how it influences our understanding and knowledge, for example by facilitating the study of climate trends and forecasting future developments.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This accurately describes the epistemological (related to knowledge and understanding) role of AI in climate science.",
          "isCorrect": false
        }
      ],
      "hint": "Epistemology is the study of knowledge. How does AI help us *know* more about the climate?"
    },
    {
      "questionNumber": 22,
      "question": "Which of these is a significant ethical challenge associated with AI's role in addressing climate change?",
      "answerOptions": [
        {
          "text": "The high cost of AI research and development.",
          "rationale": "While cost is a practical challenge, it is not a primary ethical challenge in the same way as fairness or bias.",
          "isCorrect": false
        },
        {
          "text": "The slow processing speed of current AI models.",
          "rationale": "Processing speed is a technical limitation, not an ethical challenge.",
          "isCorrect": false
        },
        {
          "text": "The significant carbon footprint of training large AI models.",
          "rationale": "The materials highlight that the computing power required for AI can consume vast amounts of energy, creating an ethical dilemma where the solution contributes to the problem.",
          "isCorrect": true
        },
        {
          "text": "The inability of AI to analyze satellite imagery.",
          "rationale": "AI is actually very proficient at analyzing satellite imagery; this is not a challenge.",
          "isCorrect": false
        }
      ],
      "hint": "Consider the environmental impact of the AI technology itself."
    },
    {
      "questionNumber": 23,
      "question": "According to Howard Gardner's theory of 'Multiple Intelligences', which of the following is a type of intelligence?",
      "answerOptions": [
        {
          "text": "Computational Intelligence",
          "rationale": "This is a term more associated with AI and is not one of Gardner's proposed intelligences.",
          "isCorrect": false
        },
        {
          "text": "Algorithmic Intelligence",
          "rationale": "This is not part of Gardner's theory, which focuses on different facets of human cognition.",
          "isCorrect": false
        },
        {
          "text": "Linguistic Intelligence",
          "rationale": "The materials list linguistic intelligence (related to language) as one of the types proposed by Howard Gardner.",
          "isCorrect": true
        },
        {
          "text": "Artificial Intelligence",
          "rationale": "Gardner's theory is about human intelligence, not artificial systems.",
          "isCorrect": false
        }
      ],
      "hint": "This theory suggests that human intelligence isn't a single entity but comprises different modalities."
    },
    {
      "questionNumber": 24,
      "question": "In which industry is AI used for predictive maintenance to monitor equipment health and reduce downtime?",
      "answerOptions": [
        {
          "text": "Education",
          "rationale": "In education, AI is used for personalized learning and administrative tasks, not heavy machinery maintenance.",
          "isCorrect": false
        },
        {
          "text": "Manufacturing",
          "rationale": "Predictive maintenance is a key application of AI in the manufacturing industry to anticipate equipment failures and schedule maintenance proactively.",
          "isCorrect": true
        },
        {
          "text": "Retail",
          "rationale": "In retail, AI is used for recommendation systems and inventory management.",
          "isCorrect": false
        },
        {
          "text": "Finance",
          "rationale": "In finance, AI is used for fraud detection and algorithmic trading.",
          "isCorrect": false
        }
      ],
      "hint": "Think about industries that rely on large, complex machinery."
    },
    {
      "questionNumber": 25,
      "question": "What is the primary difference between how AI and humans learn?",
      "answerOptions": [
        {
          "text": "Humans learn much faster than AI.",
          "rationale": "AI can often learn from vast datasets much faster than a human could process the same information.",
          "isCorrect": false
        },
        {
          "text": "AI learns from vast amounts of data, while human learning involves emotional and experiential depth.",
          "rationale": "This captures the key distinction highlighted in the materials: AI learning is data-driven, while human learning is holistic and includes consciousness and emotion.",
          "isCorrect": true
        },
        {
          "text": "Only humans can learn from their mistakes.",
          "rationale": "AI, particularly through reinforcement learning, is designed to learn from its mistakes (or 'rewards' and 'penalties').",
          "isCorrect": false
        },
        {
          "text": "AI cannot adapt its behavior over time.",
          "rationale": "Adaptability and continuous improvement are core features of machine learning in AI.",
          "isCorrect": false
        }
      ],
      "hint": "Consider the role of experience, consciousness, and emotion in the learning process."
    },
    {
      "questionNumber": 26,
      "question": "The development of the first industrial robot, Unimate, to work on an assembly line occurred in which decade?",
      "answerOptions": [
        {
          "text": "1950s",
          "rationale": "The 1950s saw the birth of AI as a concept and early programs, but the first industrial robot came later.",
          "isCorrect": false
        },
        {
          "text": "1960s",
          "rationale": "The timeline in the materials places the introduction of Unimate in 1961.",
          "isCorrect": true
        },
        {
          "text": "1970s",
          "rationale": "The 1970s saw the development of the first anthropomorphic robot in Japan and the first AI Winter.",
          "isCorrect": false
        },
        {
          "text": "1980s",
          "rationale": "The 1980s featured advancements like the first driverless car but not the first industrial robot.",
          "isCorrect": false
        }
      ],
      "hint": "This occurred the decade after AI was formally named as a field of research."
    },
    {
      "questionNumber": 27,
      "question": "true or false: Deep Learning is a branch of AI that uses a single layer of an artificial neural network.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The defining characteristic of 'deep' learning is the use of multiple layers.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "Deep learning is defined by its use of multiple layers of artificial neural networks, which allows it to learn from complex, high-dimensional data.",
          "isCorrect": true
        }
      ],
      "hint": "The word 'deep' in Deep Learning refers to the number of layers in the network."
    },
    {
      "questionNumber": 28,
      "question": "Contemporary AI is described as being 'human-centered'. What does this mean?",
      "answerOptions": [
        {
          "text": "AI systems are designed to eventually replace all human jobs.",
          "rationale": "The human-centered approach aims to augment and assist humans, not replace them.",
          "isCorrect": false
        },
        {
          "text": "AI systems are built to look and act exactly like humans.",
          "rationale": "This relates to anthropomorphism, not the principle of being human-centered, which is about purpose and values.",
          "isCorrect": false
        },
        {
          "text": "AI systems aim to enhance human capabilities and well-being, aligning with human values.",
          "rationale": "This is the correct definition provided, emphasizing collaboration and alignment with human goals and ethics.",
          "isCorrect": true
        },
        {
          "text": "AI systems can only be operated by human experts.",
          "rationale": "This is incorrect; in fact, the trend of democratized AI aims to make systems usable by everyone.",
          "isCorrect": false
        }
      ],
      "hint": "This characteristic focuses on the purpose and values guiding AI development."
    },
    {
      "questionNumber": 29,
      "question": "The ability of an organization to start and complete the execution of digital transformation plans is referred to as:",
      "answerOptions": [
        {
          "text": "Risk proclivity",
          "rationale": "Risk proclivity refers to an organization's willingness to take risks, not its ability to execute plans.",
          "isCorrect": false
        },
        {
          "text": "Inter-departmental coordination",
          "rationale": "Coordination is an enabler of change but is not the overall capacity for change itself.",
          "isCorrect": false
        },
        {
          "text": "Organizational change capacity",
          "rationale": "This intangible resource is defined as the ability to manage the transition to new processes, values, and structures, and to overcome resistance.",
          "isCorrect": true
        },
        {
          "text": "Human capital",
          "rationale": "Human capital refers to the skills and knowledge of the workforce, which contributes to change capacity but is not the capacity itself.",
          "isCorrect": false
        }
      ],
      "hint": "This intangible resource is crucial for successfully implementing new technologies and processes."
    },
    {
      "questionNumber": 30,
      "question": "Which of these is considered an intangible resource for developing AI capabilities?",
      "answerOptions": [
        {
          "text": "Cloud computing infrastructure",
          "rationale": "Technology infrastructure is listed as a tangible resource.",
          "isCorrect": false
        },
        {
          "text": "Financial investment",
          "rationale": "Financial resources are a basic, tangible resource.",
          "isCorrect": false
        },
        {
          "text": "A large, cleansed dataset",
          "rationale": "Data is considered a tangible resource that can be acquired.",
          "isCorrect": false
        },
        {
          "text": "Inter-departmental coordination",
          "rationale": "This is described as a key intangible resource that is difficult to replicate and is crucial for the success of multidisciplinary projects like AI implementation.",
          "isCorrect": true
        }
      ],
      "hint": "Intangible resources are unique to an organization and cannot be easily bought or copied."
    },
    {
      "questionNumber": 31,
      "question": "The first AI computer program, The Logic Theorist, was written in which decade?",
      "answerOptions": [
        {
          "text": "1940s",
          "rationale": "The 1940s saw the development of the first computers, but the first AI program came in the following decade.",
          "isCorrect": false
        },
        {
          "text": "1950s",
          "rationale": "The Logic Theorist was written in 1955, making the 1950s the correct decade. This was a foundational period for AI research.",
          "isCorrect": true
        },
        {
          "text": "1960s",
          "rationale": "The 1960s saw developments like the first chatbot (Eliza) and the first industrial robot.",
          "isCorrect": false
        },
        {
          "text": "1970s",
          "rationale": "The 1970s were marked by the first 'AI Winter' due to reduced funding.",
          "isCorrect": false
        }
      ],
      "hint": "This program was created just before the Dartmouth Conference where AI was officially named."
    },
    {
      "questionNumber": 32,
      "question": "What is the primary purpose of the ethical principle of Autonomy in the context of AI?",
      "answerOptions": [
        {
          "text": "To ensure AI systems can operate completely independently of humans.",
          "rationale": "This is the opposite of the principle's goal, which is to preserve human control.",
          "isCorrect": false
        },
        {
          "text": "To promote human decision-making and ensure AI systems can be overridden by people.",
          "rationale": "This correctly defines the principle, emphasizing that humans should retain the power to delegate and revoke decisions made by AI.",
          "isCorrect": true
        },
        {
          "text": "To make AI systems fair and unbiased for everyone.",
          "rationale": "This describes the principle of Justice, not Autonomy.",
          "isCorrect": false
        },
        {
          "text": "To make the inner workings of an AI system understandable.",
          "rationale": "This describes the principle of Explicability.",
          "isCorrect": false
        }
      ],
      "hint": "This principle is concerned with who has the final say in a decision."
    },
    {
      "questionNumber": 33,
      "question": "Fei-Fei Li is a key figure in AI history primarily known for her work on:",
      "answerOptions": [
        {
          "text": "Coining the term 'machine learning'.",
          "rationale": "Arthur Samuel is credited with coining the term 'machine learning'.",
          "isCorrect": false
        },
        {
          "text": "Creating the Lisp programming language.",
          "rationale": "John McCarthy developed Lisp.",
          "isCorrect": false
        },
        {
          "text": "Assembling the ImageNet dataset.",
          "rationale": "Fei-Fei Li and her colleagues assembled ImageNet, a large-scale dataset of labeled images that was pivotal for the advancement of deep learning in computer vision.",
          "isCorrect": true
        },
        {
          "text": "Developing the first chatbot, ELIZA.",
          "rationale": "Joseph Weizenbaum created ELIZA.",
          "isCorrect": false
        }
      ],
      "hint": "Her work provided the massive amount of labeled visual data needed for a major breakthrough in the 2010s."
    },
    {
      "questionNumber": 34,
      "question": "true or false: 'Soft Ethics' refers to flexible, advisory norms like codes of conduct and best practices that are encouraged but not legally binding.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "This is the correct definition. Soft ethics provides moral or professional direction rather than strict, legally enforceable rules.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This accurately describes soft ethics. Legally binding rules fall under 'hard ethics'.",
          "isCorrect": false
        }
      ],
      "hint": "Consider the difference between a company's internal guidelines and a government's data protection law."
    },
    {
      "questionNumber": 35,
      "question": "An AI system that can understand, interpret, and generate human language is primarily using which capability?",
      "answerOptions": [
        {
          "text": "Computer Vision",
          "rationale": "Computer Vision deals with interpreting visual data like images and videos, not language.",
          "isCorrect": false
        },
        {
          "text": "Robotics",
          "rationale": "Robotics involves controlling physical machines, which may use language understanding but it is not the core capability itself.",
          "isCorrect": false
        },
        {
          "text": "Natural Language Processing (NLP)",
          "rationale": "NLP is the specific branch of AI focused on the interaction between computers and human language.",
          "isCorrect": true
        },
        {
          "text": "Deep Learning",
          "rationale": "Deep Learning is a technique used to achieve NLP, but NLP is the name of the capability itself.",
          "isCorrect": false
        }
      ],
      "hint": "This capability is essential for chatbots and voice assistants."
    },
    {
      "questionNumber": 36,
      "question": "The concept of 'intergenerational equity' in environmental ethics means that:",
      "answerOptions": [
        {
          "text": "All current generations should have equal access to natural resources.",
          "rationale": "This relates more to environmental justice among contemporary populations.",
          "isCorrect": false
        },
        {
          "text": "Technological progress should be prioritized over environmental protection.",
          "rationale": "This is contrary to the principle of sustainability that underpins intergenerational equity.",
          "isCorrect": false
        },
        {
          "text": "Current actions should not compromise the ability of future generations to meet their needs.",
          "rationale": "This is the core definition of intergenerational equity, emphasizing long-term thinking and sustainability.",
          "isCorrect": true
        },
        {
          "text": "Environmental burdens should be shared equally by all countries.",
          "rationale": "This is a principle of international cooperation and justice, but not specifically 'intergenerational' equity.",
          "isCorrect": false
        }
      ],
      "hint": "This principle requires us to think about the long-term consequences of our actions on those who are not yet born."
    },
    {
      "questionNumber": 37,
      "question": "Which of these is NOT an example of a misuse of AI for social evil, according to the provided materials?",
      "answerOptions": [
        {
          "text": "Using autonomous drones for military applications.",
          "rationale": "Automated warfare and lethal autonomous weapons are listed as a significant misuse and ethical concern.",
          "isCorrect": false
        },
        {
          "text": "Deploying biased algorithms in law enforcement that discriminate against minority groups.",
          "rationale": "Discriminatory algorithms are explicitly mentioned as a way AI can perpetuate social inequalities.",
          "isCorrect": false
        },
        {
          "text": "Using AI to optimize a city's traffic flow to reduce congestion and pollution.",
          "rationale": "This is an example of using AI for social good (improving efficiency and environmental impact), not for social evil.",
          "isCorrect": true
        },
        {
          "text": "Creating deepfake videos to damage the reputation of a political opponent.",
          "rationale": "Deepfakes and disinformation are highlighted as a major misuse of AI that can manipulate public opinion.",
          "isCorrect": false
        }
      ],
      "hint": "Look for the option that describes a positive, beneficial application of AI."
    },
    {
      "questionNumber": 38,
      "question": "What is a primary difference between human creativity and AI-generated creativity?",
      "answerOptions": [
        {
          "text": "AI cannot generate any creative output like art or music.",
          "rationale": "AI can and does generate creative outputs, but the underlying process is different.",
          "isCorrect": false
        },
        {
          "text": "Human creativity is driven by consciousness and emotions, while AI generates content based on learned patterns.",
          "rationale": "The materials emphasize that AI can mimic creative processes but lacks the genuine, innate creativity driven by human consciousness.",
          "isCorrect": true
        },
        {
          "text": "AI is more creative than humans in every domain.",
          "rationale": "This is a subjective claim and not supported by the materials, which highlight the unique nature of human creativity.",
          "isCorrect": false
        },
        {
          "text": "Humans can only be creative in one domain, while AI can be creative in many.",
          "rationale": "Humans can be creative across many domains, and AI's creativity is also dependent on its training data for each domain.",
          "isCorrect": false
        }
      ],
      "hint": "Think about the role of consciousness and original thought versus pattern recognition."
    },
    {
      "questionNumber": 39,
      "question": "The 'Turing Test', proposed by Alan Turing in 1950, was designed to test a machine's ability to:",
      "answerOptions": [
        {
          "text": "Solve complex mathematical equations faster than a human.",
          "rationale": "Computers were already known to be faster at calculation. The test aimed for something more subtle.",
          "isCorrect": false
        },
        {
          "text": "Exhibit intelligent behavior equivalent to, or indistinguishable from, that of a human.",
          "rationale": "This is the essence of the Turing Test, where a human evaluator judges natural language conversations between a human and a machine.",
          "isCorrect": true
        },
        {
          "text": "Physically manipulate objects in the real world.",
          "rationale": "This relates to robotics, not the conversational intelligence that the Turing Test was designed to assess.",
          "isCorrect": false
        },
        {
          "text": "Learn from a new dataset without human intervention.",
          "rationale": "This describes a capability of machine learning, but the Turing Test is about the outcome of behavior, not the learning process.",
          "isCorrect": false
        }
      ],
      "hint": "This famous test involves a human judge conversing with both a human and a machine."
    },
    {
      "questionNumber": 40,
      "question": "true or false: The 'AI Winter' of the 1970s was a period of increased funding and rapid progress in AI research.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The term 'AI Winter' describes a period of reduced funding and interest.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "The AI Winter was characterized by significant reductions in funding (e.g., from the British government) and a slowdown in progress due to unfulfilled promises.",
          "isCorrect": true
        }
      ],
      "hint": "Consider what the term 'winter' metaphorically implies in this context."
    },
    {
      "questionNumber": 41,
      "question": "Which machine learning paradigm involves an agent learning to make decisions by receiving rewards or punishments?",
      "answerOptions": [
        {
          "text": "Supervised Learning",
          "rationale": "Supervised learning uses labeled data where the correct output is already known.",
          "isCorrect": false
        },
        {
          "text": "Unsupervised Learning",
          "rationale": "Unsupervised learning finds patterns in unlabeled data without feedback on correctness.",
          "isCorrect": false
        },
        {
          "text": "Reinforcement Learning",
          "rationale": "This is the correct definition. The agent learns through trial and error in an environment to maximize its cumulative reward.",
          "isCorrect": true
        },
        {
          "text": "Deep Learning",
          "rationale": "Deep learning is a technique that can be used within any of the three paradigms, but it is not a paradigm itself.",
          "isCorrect": false
        }
      ],
      "hint": "This type of learning is often compared to training a pet with treats."
    },
    {
      "questionNumber": 42,
      "question": "In the context of AI ethics, what does 'traceability' refer to?",
      "answerOptions": [
        {
          "text": "The ability of an AI to track users' locations.",
          "rationale": "This is a privacy concern, not the definition of traceability.",
          "isCorrect": false
        },
        {
          "text": "The broader impact that algorithms have on society.",
          "rationale": "This describes 'Transformative Effects'.",
          "isCorrect": false
        },
        {
          "text": "The ability to track and understand the decision-making process of an algorithm.",
          "rationale": "This is the correct definition. Traceability is essential for accountability and debugging.",
          "isCorrect": true
        },
        {
          "text": "The process of removing bias from a dataset.",
          "rationale": "This is a technique for promoting fairness, but it is not what traceability means.",
          "isCorrect": false
        }
      ],
      "hint": "This concept is crucial for holding an algorithm accountable for its decisions."
    },
    {
      "questionNumber": 43,
      "question": "What was the significance of IBM's Watson winning the game show Jeopardy! in 2011?",
      "answerOptions": [
        {
          "text": "It was the first time a computer beat a human at chess.",
          "rationale": "That milestone was achieved by IBM's Deep Blue in 1997.",
          "isCorrect": false
        },
        {
          "text": "It demonstrated a major leap in natural language processing and understanding.",
          "rationale": "Jeopardy! requires understanding nuance, puns, and complex language, so Watson's victory was a significant achievement for NLP.",
          "isCorrect": true
        },
        {
          "text": "It was the first use of a neural network in a public demonstration.",
          "rationale": "Neural networks had been used for decades before this.",
          "isCorrect": false
        },
        {
          "text": "It proved that computers could experience human emotions.",
          "rationale": "Watson's performance was about processing information, not feeling emotions.",
          "isCorrect": false
        }
      ],
      "hint": "Think about the skills needed to play Jeopardy! beyond simple fact retrieval."
    },
    {
      "questionNumber": 44,
      "question": "true or false: The principle of Justice in AI ethics suggests that the benefits of AI should be shared and that AI should not create or worsen unfair discrimination.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "This is the core of the Justice principle, which encompasses fairness, shared prosperity, and the elimination of discrimination.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This accurately describes the ethical principle of Justice as applied to AI.",
          "isCorrect": false
        }
      ],
      "hint": "This principle is about fairness and equity in the distribution of AI's benefits and burdens."
    },
    {
      "questionNumber": 45,
      "question": "A personal assistant like Siri or Alexa is an example of what type of AI?",
      "answerOptions": [
        {
          "text": "Autonomous AI",
          "rationale": "While it has some autonomous functions, its primary role is interaction, not independent physical action like a self-driving car.",
          "isCorrect": false
        },
        {
          "text": "Generative AI",
          "rationale": "While modern versions use generative models to formulate answers, their overall category is defined by their interactive function.",
          "isCorrect": false
        },
        {
          "text": "Conversational AI",
          "rationale": "These systems are designed for natural, seamless interaction between humans and machines using voice or text, which is the definition of Conversational AI.",
          "isCorrect": true
        },
        {
          "text": "Explainable AI",
          "rationale": "Explainable AI is a characteristic or goal for AI systems, not a type of application like a virtual assistant.",
          "isCorrect": false
        }
      ],
      "hint": "What is the primary way you interact with these devices?"
    },
    {
      "questionNumber": 46,
      "question": "What is a major challenge for AI in the transportation industry, particularly for autonomous vehicles?",
      "answerOptions": [
        {
          "text": "Lack of high-quality data from sensors.",
          "rationale": "Modern vehicles are equipped with numerous high-quality sensors; the challenge is processing this data reliably.",
          "isCorrect": false
        },
        {
          "text": "Regulatory and safety concerns.",
          "rationale": "The materials highlight regulatory hurdles, safety validation, and public trust as significant challenges for the widespread adoption of autonomous vehicles.",
          "isCorrect": true
        },
        {
          "text": "Inability to optimize traffic flow.",
          "rationale": "AI is actually very good at optimizing complex systems like traffic flow.",
          "isCorrect": false
        },
        {
          "text": "High fuel consumption.",
          "rationale": "AI is often used to optimize fuel consumption, making this a benefit, not a challenge.",
          "isCorrect": false
        }
      ],
      "hint": "Think about the legal and public acceptance issues surrounding self-driving cars."
    },
    {
      "questionNumber": 47,
      "question": "'Robotic Process Automation' (RPA) is a technology that:",
      "answerOptions": [
        {
          "text": "Allows robots to feel human emotions.",
          "rationale": "RPA is about automating tasks, not about creating emotional intelligence.",
          "isCorrect": false
        },
        {
          "text": "Automates repetitive, rule-based tasks using software robots.",
          "rationale": "This is the correct definition. RPA is used to handle high-volume, repeatable tasks that previously required humans to perform.",
          "isCorrect": true
        },
        {
          "text": "Builds physical, humanoid robots for manufacturing.",
          "rationale": "RPA uses 'software robots' (bots), not physical hardware.",
          "isCorrect": false
        },
        {
          "text": "Creates new and original works of art.",
          "rationale": "This is a function of Generative AI, not RPA.",
          "isCorrect": false
        }
      ],
      "hint": "This technology is often used for back-office tasks like data entry and processing."
    },
    {
      "questionNumber": 48,
      "question": "The 'black box' problem in AI, where it is difficult to understand how a system arrived at a conclusion, relates most directly to which ethical principle?",
      "answerOptions": [
        {
          "text": "Justice",
          "rationale": "While a lack of transparency can lead to unjust outcomes, the core problem of the 'black box' is about understandability.",
          "isCorrect": false
        },
        {
          "text": "Beneficence",
          "rationale": "Beneficence is about doing good. The 'black box' problem is about a lack of transparency.",
          "isCorrect": false
        },
        {
          "text": "Autonomy",
          "rationale": "Autonomy is about human control. While related, the 'black box' problem is specifically about the lack of insight into the AI's process.",
          "isCorrect": false
        },
        {
          "text": "Explicability",
          "rationale": "The 'black box' nature of some AI systems is the primary challenge that the principle of Explicability (intelligibility and accountability) seeks to address.",
          "isCorrect": true
        }
      ],
      "hint": "Which principle is focused on making AI systems transparent and understandable?"
    },
    {
      "questionNumber": 49,
      "question": "Which one of these is NOT a component of human agency as described in the materials?",
      "answerOptions": [
        {
          "text": "Consciousness",
          "rationale": "Consciousness, or awareness of self and environment, is listed as a key component of human agency.",
          "isCorrect": false
        },
        {
          "text": "Data Processing",
          "rationale": "While humans process data, the term is more associated with the computational function of AI. Human agency is defined by higher-level cognitive and emotional traits.",
          "isCorrect": true
        },
        {
          "text": "Emotional Intelligence",
          "rationale": "The ability to understand and manage emotions is listed as a crucial part of human agency.",
          "isCorrect": false
        },
        {
          "text": "Creativity",
          "rationale": "The capacity to generate original ideas is highlighted as a component of human agency.",
          "isCorrect": false
        }
      ],
      "hint": "Look for the term that describes a machine-like function rather than a cognitive or emotional one."
    },
    {
      "questionNumber": 50,
      "question": "true or false: The development of powerful GPUs (Graphics Processing Units) was a key factor in the resurgence of AI and the success of deep learning.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The materials state that advances in hardware, especially GPUs, enabled the training of complex models that fueled the deep learning era.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "GPUs, with their parallel processing capabilities, were crucial for handling the massive computational requirements of training deep neural networks.",
          "isCorrect": false
        }
      ],
      "hint": "Deep learning models require massive amounts of parallel computation. What kind of hardware is good at that?"
    },
    {
      "questionNumber": 51,
      "question": "In what year was OpenAI's influential GPT-3 language model introduced?",
      "answerOptions": [
        {
          "text": "2012",
          "rationale": "2012 was a key year for the ImageNet breakthrough in deep learning.",
          "isCorrect": false
        },
        {
          "text": "2018",
          "rationale": "This is close, but the specific year mentioned for GPT-3's introduction is later.",
          "isCorrect": false
        },
        {
          "text": "2020",
          "rationale": "The provided timelines and summary sheet identify 2020 as the year GPT-3 was released.",
          "isCorrect": true
        },
        {
          "text": "2023",
          "rationale": "By 2023, generative AI was being integrated into the business world, but GPT-3 was released earlier.",
          "isCorrect": false
        }
      ],
      "hint": "This milestone occurred at the beginning of the current decade."
    },
    {
      "questionNumber": 52,
      "question": "What is the primary goal of using AI for a 'circular economy'?",
      "answerOptions": [
        {
          "text": "To increase the production of single-use products.",
          "rationale": "A circular economy aims to reduce waste, which is the opposite of promoting single-use products.",
          "isCorrect": false
        },
        {
          "text": "To analyze financial markets for optimal trading strategies.",
          "rationale": "This is an application of AI in finance, not in the context of a circular economy.",
          "isCorrect": false
        },
        {
          "text": "To use big data analytics for waste reduction and sustainable supply chains.",
          "rationale": "This aligns with the goals of a circular economy, which focuses on minimizing waste and maximizing the reuse of resources. AI can optimize these processes.",
          "isCorrect": true
        },
        {
          "text": "To create more effective marketing campaigns.",
          "rationale": "This is a commercial application of AI and is not directly related to the principles of a circular economy.",
          "isCorrect": false
        }
      ],
      "hint": "A circular economy is a model of production and consumption which involves sharing, leasing, reusing, repairing, refurbishing and recycling existing materials and products."
    },
    {
      "questionNumber": 53,
      "question": "According to the materials, 'AI must ensure basic preconditions for life, continued prosperity, and a good environment for future generations.' This statement is most closely aligned with which ethical principle?",
      "answerOptions": [
        {
          "text": "Justice",
          "rationale": "While related, this statement's focus on promoting well-being and sustainability is a core tenet of another principle.",
          "isCorrect": false
        },
        {
          "text": "Beneficence",
          "rationale": "This broad goal of promoting positive outcomes for humanity and the planet is a key aspect of beneficence, as described by the European Group on Ethics (EGE).",
          "isCorrect": true
        },
        {
          "text": "Autonomy",
          "rationale": "Autonomy focuses on human control and choice, not the overall outcome of AI's impact on the world.",
          "isCorrect": false
        },
        {
          "text": "Explicability",
          "rationale": "Explicability is about transparency and accountability, which helps ensure beneficence but is not the principle itself.",
          "isCorrect": false
        }
      ],
      "hint": "This principle is about doing good on a grand scale, considering all of humanity and the planet."
    },
    {
      "questionNumber": 54,
      "question": "Which of these is an example of 'tangible resources' needed for AI development?",
      "answerOptions": [
        {
          "text": "Organizational change capacity",
          "rationale": "This is listed as an intangible resource, as it's a quality of the organization's culture and processes.",
          "isCorrect": false
        },
        {
          "text": "Technical skills of employees",
          "rationale": "Skills are part of human capital, which is categorized under intangible resources.",
          "isCorrect": false
        },
        {
          "text": "Cloud computing infrastructure and data",
          "rationale": "Technology infrastructure and data are described as tangible resources that can be acquired.",
          "isCorrect": true
        },
        {
          "text": "Inter-departmental coordination",
          "rationale": "This is described as a key intangible resource.",
          "isCorrect": false
        }
      ],
      "hint": "Tangible resources are assets that can be physically touched or are easily quantifiable and acquirable."
    },
    {
      "questionNumber": 55,
      "question": "The 'epistemic' factors in the map of algorithm ethics refer to:",
      "answerOptions": [
        {
          "text": "The moral and ethical impact of an algorithm's decisions.",
          "rationale": "This describes the 'normative' concerns.",
          "isCorrect": false
        },
        {
          "text": "The quality and accuracy of the data and the justifiability of conclusions.",
          "rationale": "Epistemic concerns are related to knowledge, evidence, and justification. This includes issues like inconclusive or misguided evidence.",
          "isCorrect": true
        },
        {
          "text": "The financial cost of developing the algorithm.",
          "rationale": "This is an economic or practical concern, not an epistemic one.",
          "isCorrect": false
        },
        {
          "text": "The ability to trace the decision-making process of the algorithm.",
          "rationale": "While related, traceability is listed as its own category of concern that bridges epistemic and normative issues.",
          "isCorrect": false
        }
      ],
      "hint": "This category of concern relates to the evidence and knowledge an algorithm uses."
    },
    {
      "questionNumber": 56,
      "question": "true or false: The Asilomar Principles warn against a potential AI arms race.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The materials state that the Asilomar Principles warn against an arms race and recursive self-improvement as part of the principle of nonmaleficence.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This is a key point from the Asilomar AI Principles, focusing on preventing the misuse of AI.",
          "isCorrect": false
        }
      ],
      "hint": "These principles were established at a 2017 conference to guide AI development safely."
    },
    {
      "questionNumber": 57,
      "question": "What is 'human agency'?",
      "answerOptions": [
        {
          "text": "An organization that promotes human rights.",
          "rationale": "This is a literal interpretation of the words, but not the correct definition in this philosophical context.",
          "isCorrect": false
        },
        {
          "text": "The capacity of humans to make choices and impose those choices on the world.",
          "rationale": "This is the precise definition given in the materials, involving independent action and decision-making.",
          "isCorrect": true
        },
        {
          "text": "The biological process of human evolution.",
          "rationale": "This is a biological concept, not one related to individual capacity for choice.",
          "isCorrect": false
        },
        {
          "text": "The total population of humans on Earth.",
          "rationale": "This is a demographic statistic, not a term for individual capability.",
          "isCorrect": false
        }
      ],
      "hint": "This term refers to our ability to act as independent agents in the world."
    },
    {
      "questionNumber": 58,
      "question": "Which of these is NOT a characteristic of contemporary AI?",
      "answerOptions": [
        {
          "text": "Data-driven",
          "rationale": "Contemporary AI is heavily reliant on large datasets for learning.",
          "isCorrect": false
        },
        {
          "text": "Domain-specific",
          "rationale": "Most current AI is 'narrow AI', designed for specific tasks rather than general intelligence.",
          "isCorrect": false
        },
        {
          "text": "Rule-based",
          "rationale": "While early AI (Symbolic AI/GOFAI) was rule-based, contemporary AI is primarily characterized by learning from data, not explicit rules.",
          "isCorrect": true
        },
        {
          "text": "Human-centered",
          "rationale": "The goal of modern AI development is often described as augmenting and assisting humans.",
          "isCorrect": false
        }
      ],
      "hint": "Think about the shift from early AI approaches to modern machine learning."
    },
    {
      "questionNumber": 59,
      "question": "When an AI system's autonomy grows to the point where it undermines a human's ability to make their own choices, it violates the principle of:",
      "answerOptions": [
        {
          "text": "Justice",
          "rationale": "Justice is about fairness. The issue described here is about control and decision-making power.",
          "isCorrect": false
        },
        {
          "text": "Human Autonomy",
          "rationale": "The materials explicitly state that a risk of growing AI autonomy is the undermining of human autonomy. The principle seeks to balance these two.",
          "isCorrect": true
        },
        {
          "text": "Beneficence",
          "rationale": "While undermining human choice could be seen as harmful (violating nonmaleficence), the direct principle at play is Autonomy.",
          "isCorrect": false
        },
        {
          "text": "Explicability",
          "rationale": "A lack of explicability might make it hard to know if autonomy is being undermined, but autonomy is the principle being violated.",
          "isCorrect": false
        }
      ],
      "hint": "The name of the principle is directly related to the concept being undermined."
    },
    {
      "questionNumber": 60,
      "question": "The concept of 'meta-autonomy' in AI ethics refers to:",
      "answerOptions": [
        {
          "text": "An AI that has become fully self-aware.",
          "rationale": "This is a concept from science fiction (sentience/AGI), not the definition of meta-autonomy.",
          "isCorrect": false
        },
        {
          "text": "The human's power to decide which decisions to delegate to an AI.",
          "rationale": "This is the correct definition. It's the 'decision about the decision', where humans retain ultimate control over what tasks are delegated.",
          "isCorrect": true
        },
        {
          "text": "An AI that can override its own programming.",
          "rationale": "This describes recursive self-improvement, a different and more speculative concept.",
          "isCorrect": false
        },
        {
          "text": "A network of autonomous AI agents working together.",
          "rationale": "This describes a multi-agent system, not meta-autonomy.",
          "isCorrect": false
        }
      ],
      "hint": "'Meta' often means 'about' or 'at a higher level'. This is about the decision *about* delegating."
    },
    {
      "questionNumber": 61,
      "question": "In which decade did the movie 'Metropolis' feature the first on-screen portrayal of a robot?",
      "answerOptions": [
        {
          "text": "1920s",
          "rationale": "The materials list the film 'Metropolis' and its influential robot portrayal under the year 1927.",
          "isCorrect": true
        },
        {
          "text": "1940s",
          "rationale": "The 1940s were focused on the development of the first actual computers.",
          "isCorrect": false
        },
        {
          "text": "1960s",
          "rationale": "The 1960s featured the AI HAL in '2001: A Space Odyssey', but 'Metropolis' came much earlier.",
          "isCorrect": false
        },
        {
          "text": "1980s",
          "rationale": "The 1980s gave us 'The Terminator', but the first on-screen robot was decades prior.",
          "isCorrect": false
        }
      ],
      "hint": "This classic silent film was released before the advent of the first electronic computers."
    },
    {
      "questionNumber": 62,
      "question": "Which of these is an example of an epistemic concern in algorithmic ethics?",
      "answerOptions": [
        {
          "text": "Unfair Outcomes",
          "rationale": "Unfair outcomes are a normative concern, dealing with the ethical impact of a decision.",
          "isCorrect": false
        },
        {
          "text": "Inconclusive Evidence",
          "rationale": "This is an epistemic concern, as it deals with the quality and sufficiency of the knowledge (data) the algorithm is using.",
          "isCorrect": true
        },
        {
          "text": "Transformative Effects",
          "rationale": "Transformative effects on society are a normative concern.",
          "isCorrect": false
        },
        {
          "text": "Moral Responsibility",
          "rationale": "This is an ethical challenge related to traceability, which bridges both normative and epistemic concerns.",
          "isCorrect": false
        }
      ],
      "hint": "Epistemic concerns are about knowledge and evidence. Which option relates to the quality of the information used?"
    },
    {
      "questionNumber": 63,
      "question": "What does the term 'AI Winter' refer to in the history of artificial intelligence?",
      "answerOptions": [
        {
          "text": "A period of rapid innovation and breakthroughs.",
          "rationale": "This is the opposite of an AI winter.",
          "isCorrect": false
        },
        {
          "text": "A time when AI becomes dangerously intelligent.",
          "rationale": "This is a science fiction concept, not a historical period.",
          "isCorrect": false
        },
        {
          "text": "A period of reduced funding and interest in AI research.",
          "rationale": "This is the correct definition. The first AI winter occurred in the 1970s when early promises were not met, leading to cuts in research funding.",
          "isCorrect": true
        },
        {
          "text": "The annual conference for AI researchers held in a cold climate.",
          "rationale": "This is an incorrect, literal interpretation.",
          "isCorrect": false
        }
      ],
      "hint": "Think about what the season 'winter' symbolizes in terms of growth and activity."
    },
    {
      "questionNumber": 64,
      "question": "true or false: The principle of 'Situational Fairness' in AI for Social Good suggests that variables and proxies irrelevant to an outcome should always be removed from a dataset.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The statement is mostly correct but misses a key exception mentioned in the text.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "The principle states they should be removed *except* when their inclusion supports inclusivity, safety, or other ethical imperatives. The exception is a critical part of the definition.",
          "isCorrect": true
        }
      ],
      "hint": "Does the principle allow for any exceptions to this rule?"
    },
    {
      "questionNumber": 65,
      "question": "What is 'intergenerational equity' in the context of environmental sustainability?",
      "answerOptions": [
        {
          "text": "Ensuring all people alive today have equal access to resources.",
          "rationale": "This is an issue of contemporary environmental justice, not intergenerational equity.",
          "isCorrect": false
        },
        {
          "text": "Considering the needs of future generations in current environmental decisions.",
          "rationale": "This is the correct definition, emphasizing that our actions today should not compromise the well-being of those who come after us.",
          "isCorrect": true
        },
        {
          "text": "Using technology to generate equal outcomes for everyone.",
          "rationale": "This is a broader concept of equity, not specific to the intergenerational environmental context.",
          "isCorrect": false
        },
        {
          "text": "Balancing the economic needs of different generations.",
          "rationale": "While related, the core focus of 'intergenerational equity' in this context is on environmental resources and a livable planet.",
          "isCorrect": false
        }
      ],
      "hint": "This concept looks at fairness across time, between us and our descendants."
    },
    {
      "questionNumber": 66,
      "question": "A key challenge of AI in education is:",
      "answerOptions": [
        {
          "text": "The inability of AI to grade assignments.",
          "rationale": "AI is increasingly used for automated grading, so this is not a primary challenge.",
          "isCorrect": false
        },
        {
          "text": "Ensuring equity and access to AI-driven tools for all students.",
          "rationale": "The materials highlight this as a major challenge, as a digital divide could exacerbate educational inequalities.",
          "isCorrect": true
        },
        {
          "text": "The high cost of electricity to run educational software.",
          "rationale": "While a factor, the issue of equity and access is a more significant ethical and social challenge.",
          "isCorrect": false
        },
        {
          "text": "The lack of data on student performance.",
          "rationale": "Educational systems generate vast amounts of student data that AI can analyze.",
          "isCorrect": false
        }
      ],
      "hint": "Consider how the introduction of expensive new technologies might affect students from different socioeconomic backgrounds."
    },
    {
      "questionNumber": 67,
      "question": "What is the primary difference between Deep Learning and Machine Learning?",
      "answerOptions": [
        {
          "text": "There is no difference; the terms are interchangeable.",
          "rationale": "Deep Learning is a specific type of Machine Learning.",
          "isCorrect": false
        },
        {
          "text": "Machine Learning uses neural networks, while Deep Learning does not.",
          "rationale": "This is incorrect. Deep Learning is characterized by its use of neural networks with many layers.",
          "isCorrect": false
        },
        {
          "text": "Deep Learning is a subset of Machine Learning that uses neural networks with multiple layers.",
          "rationale": "This correctly identifies Deep Learning as a specific, more complex form of Machine Learning that utilizes 'deep' neural networks.",
          "isCorrect": true
        },
        {
          "text": "Machine Learning is for images, and Deep Learning is for text.",
          "rationale": "Both techniques can be applied to various data types, including images and text.",
          "isCorrect": false
        }
      ],
      "hint": "One of these terms is a subfield of the other."
    },
    {
      "questionNumber": 68,
      "question": "The ethical principle that requires AI systems to promote well-being, preserve dignity, and sustain the planet is:",
      "answerOptions": [
        {
          "text": "Justice",
          "rationale": "Justice is about fairness and non-discrimination.",
          "isCorrect": false
        },
        {
          "text": "Beneficence",
          "rationale": "This broad, positive mandate to do good for humanity and the environment is the core of the Beneficence principle.",
          "isCorrect": true
        },
        {
          "text": "Autonomy",
          "rationale": "Autonomy is about preserving human control.",
          "isCorrect": false
        },
        {
          "text": "Nonmaleficence",
          "rationale": "Nonmaleficence is about avoiding harm, which is a more passive requirement than actively promoting well-being.",
          "isCorrect": false
        }
      ],
      "hint": "This is the 'do good' principle."
    },
    {
      "questionNumber": 69,
      "question": "What does the 'attribution problem' in AI crime refer to?",
      "answerOptions": [
        {
          "text": "The problem of AI systems making false attributions in text.",
          "rationale": "This is a performance issue (hallucination), not the legal concept of the attribution problem.",
          "isCorrect": false
        },
        {
          "text": "The difficulty in tracing accountability for an AI's actions back to a human.",
          "rationale": "This is the correct definition. The autonomous nature of AI can make it hard to determine who is legally responsible for a crime it commits or facilitates.",
          "isCorrect": true
        },
        {
          "text": "The challenge of attributing human-like consciousness to an AI.",
          "rationale": "This is a philosophical question about sentience, not a legal one about crime.",
          "isCorrect": false
        },
        {
          "text": "The problem of AI systems not giving proper credit to their data sources.",
          "rationale": "This is an issue of academic or intellectual property citation, not criminal liability.",
          "isCorrect": false
        }
      ],
      "hint": "This problem is about assigning legal responsibility when a crime occurs."
    },
    {
      "questionNumber": 70,
      "question": "true or false: 'Hard Ethics' consists of legally binding rules and regulations with enforceable consequences.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "This is the definition provided in the materials, contrasting it with the advisory nature of 'soft ethics'. Examples include laws like GDPR.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This accurately describes 'hard ethics'.",
          "isCorrect": false
        }
      ],
      "hint": "Think about the difference between a law and a guideline."
    },
    {
      "questionNumber": 71,
      "question": "Which of these represents a 'normative' concern in the ethics of algorithms?",
      "answerOptions": [
        {
          "text": "Inconclusive Evidence",
          "rationale": "This is an epistemic concern, related to the quality of the data.",
          "isCorrect": false
        },
        {
          "text": "Inscrutable Evidence",
          "rationale": "This is an epistemic concern, related to the interpretability of the data.",
          "isCorrect": false
        },
        {
          "text": "Misguided Evidence",
          "rationale": "This is an epistemic concern, related to flaws or bias in the data.",
          "isCorrect": false
        },
        {
          "text": "Unfair Outcomes",
          "rationale": "This is a normative concern, as it refers to the ethical impact and justice of the algorithm's decisions and actions.",
          "isCorrect": true
        }
      ],
      "hint": "Normative concerns deal with the moral value and impact of an action, asking what 'should' or 'should not' happen."
    },
    {
      "questionNumber": 72,
      "question": "The concept of 'human-friendly semanticization' means that AI should:",
      "answerOptions": [
        {
          "text": "Use complex technical jargon to be more precise.",
          "rationale": "This is the opposite of the principle's goal, which is to be intuitive and meaningful to humans.",
          "isCorrect": false
        },
        {
          "text": "Not hinder the ability for people to give meaning to and make sense of something.",
          "rationale": "This is the correct definition. It means AI communication should be intuitive and meaningful, supporting human understanding rather than complicating it.",
          "isCorrect": true
        },
        {
          "text": "Translate all human languages into a single machine language.",
          "rationale": "This is a technical process, not the principle of making AI interactions meaningful and understandable.",
          "isCorrect": false
        },
        {
          "text": "Prioritize computational efficiency over user experience.",
          "rationale": "This principle prioritizes the human user's ability to understand and engage with the AI.",
          "isCorrect": false
        }
      ],
      "hint": "This AI for Social Good factor focuses on making AI interactions natural and understandable for people."
    },
    {
      "questionNumber": 73,
      "question": "What is the primary challenge associated with the 'black box' nature of some advanced AI systems?",
      "answerOptions": [
        {
          "text": "High energy consumption",
          "rationale": "Energy consumption is a separate issue related to Green AI.",
          "isCorrect": false
        },
        {
          "text": "Slow processing speeds",
          "rationale": "Many advanced AI systems are extremely fast; the problem is not speed but transparency.",
          "isCorrect": false
        },
        {
          "text": "Difficulty in understanding how they make decisions",
          "rationale": "The 'black box' problem refers to the lack of transparency and explainability, making it hard to trust, debug, or hold the system accountable.",
          "isCorrect": true
        },
        {
          "text": "Inability to learn from new data",
          "rationale": "The ability to learn from new data is a key strength of these systems.",
          "isCorrect": false
        }
      ],
      "hint": "This problem relates directly to the ethical principle of Explicability."
    },
    {
      "questionNumber": 74,
      "question": "A key benefit of AI in the retail industry is:",
      "answerOptions": [
        {
          "text": "Predictive maintenance on shopping carts.",
          "rationale": "This is not a primary application of AI in retail.",
          "isCorrect": false
        },
        {
          "text": "Personalized shopping experiences through recommendation systems.",
          "rationale": "The materials highlight personalization via recommendation engines (like on Netflix and Amazon) as a key application and benefit in retail.",
          "isCorrect": true
        },
        {
          "text": "Diagnosing illnesses in customers.",
          "rationale": "This is an application for the healthcare industry, not retail.",
          "isCorrect": false
        },
        {
          "text": "Automating the entire supply chain with physical robots.",
          "rationale": "While AI helps optimize supply chains, full automation with physical robots is more characteristic of manufacturing and logistics.",
          "isCorrect": false
        }
      ],
      "hint": "Think about how online stores suggest products you might like."
    },
    {
      "questionNumber": 75,
      "question": "true or false: According to Robert Sternberg's Triarchic Theory, intelligence is composed of analytical, creative, and practical aspects.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The materials correctly state that Sternberg's Triarchic Theory proposes these three types of intelligence.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This is an accurate representation of Sternberg's theory as described in the documents.",
          "isCorrect": false
        }
      ],
      "hint": "This is one of the two major theories of human intelligence mentioned."
    },
    {
      "questionNumber": 76,
      "question": "Which of the following historical developments was NOT mentioned as being part of the 1950s?",
      "answerOptions": [
        {
          "text": "Alan Turing publishes 'Computing Machinery and Intelligence'.",
          "rationale": "This foundational paper was published in 1950.",
          "isCorrect": false
        },
        {
          "text": "The first chatbot, ELIZA, is developed.",
          "rationale": "ELIZA was developed by Joseph Weizenbaum in 1966, during the 1960s.",
          "isCorrect": true
        },
        {
          "text": "John McCarthy coins the term 'artificial intelligence'.",
          "rationale": "This occurred at the Dartmouth Conference in 1956.",
          "isCorrect": false
        },
        {
          "text": "Arthur Samuel develops a program for playing checkers.",
          "rationale": "Samuel's checkers program was a key development in machine learning during the 1950s.",
          "isCorrect": false
        }
      ],
      "hint": "Look for the event that occurred in the decade following the 1950s."
    },
    {
      "questionNumber": 77,
      "question": "The 'feasibility problem' in monitoring AI crime refers to the fact that:",
      "answerOptions": [
        {
          "text": "It is not financially feasible to monitor all AI systems.",
          "rationale": "While cost can be a factor, the feasibility problem described is technical in nature.",
          "isCorrect": false
        },
        {
          "text": "Some AI systems operate at speeds and complexity beyond human monitoring capabilities.",
          "rationale": "This is the correct definition. The speed of AI actions, such as in high-frequency trading or bot networks, makes traditional compliance monitoring unfeasible.",
          "isCorrect": true
        },
        {
          "text": "It is not legally feasible to hold an AI accountable for a crime.",
          "rationale": "This relates to the attribution problem and legal frameworks, not the technical challenge of monitoring.",
          "isCorrect": false
        },
        {
          "text": "AI crime is not a feasible threat in the near future.",
          "rationale": "The materials clearly treat AI crime as a current and growing threat.",
          "isCorrect": false
        }
      ],
      "hint": "This challenge relates to the speed and scale at which AI can operate."
    },
    {
      "questionNumber": 78,
      "question": "Which ethical framework did Luciano Floridi align the various proposed AI principles with, adding one new principle?",
      "answerOptions": [
        {
          "text": "Utilitarianism",
          "rationale": "Utilitarianism is a broader ethical theory, not the specific framework mentioned.",
          "isCorrect": false
        },
        {
          "text": "Deontology",
          "rationale": "Deontology is a broader ethical theory focused on rules and duties.",
          "isCorrect": false
        },
        {
          "text": "The framework used in bioethics",
          "rationale": "The materials state that Floridi aligned the proposed AI principles with the four basic principles from bioethics (Beneficence, Nonmaleficence, Autonomy, Justice).",
          "isCorrect": true
        },
        {
          "text": "The Asilomar AI Principles",
          "rationale": "The Asilomar principles are one of the sets of guidelines he analyzed, not the framework he used for alignment.",
          "isCorrect": false
        }
      ],
      "hint": "This framework comes from the field of medical ethics."
    },
    {
      "questionNumber": 79,
      "question": "What was the fifth principle Floridi added to the bioethics framework to create a comprehensive framework for AI ethics?",
      "answerOptions": [
        {
          "text": "Privacy",
          "rationale": "Privacy is a key concern but is often considered under Nonmaleficence (preventing harm) and Autonomy (control over personal data).",
          "isCorrect": false
        },
        {
          "text": "Sustainability",
          "rationale": "Sustainability is a goal often discussed under Beneficence.",
          "isCorrect": false
        },
        {
          "text": "Explicability",
          "rationale": "Explicability (intelligibility + accountability) was the new, AI-specific principle added because of the unique 'black box' challenges of AI.",
          "isCorrect": true
        },
        {
          "text": "Efficiency",
          "rationale": "Efficiency is a technical goal, not a core ethical principle in this framework.",
          "isCorrect": false
        }
      ],
      "hint": "This principle is unique to AI and addresses its often opaque nature."
    },
    {
      "questionNumber": 80,
      "question": "true or false: The use of AI in financial markets can include both beneficial applications like fraud detection and malicious uses like market manipulation.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The materials describe both positive applications in the finance industry (fraud detection, algorithmic trading) and misuses for social evil (economic manipulation).",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "AI is a dual-use technology, and the financial sector is a prime example of where it can be used for both good and ill.",
          "isCorrect": false
        }
      ],
      "hint": "Consider the dual-use nature of powerful technologies."
    },
    {
      "questionNumber": 81,
      "question": "The term 'Good Old-Fashioned AI' (GOFAI) is another name for which approach to AI?",
      "answerOptions": [
        {
          "text": "Deep Learning",
          "rationale": "Deep Learning is a modern, data-driven approach, the opposite of GOFAI.",
          "isCorrect": false
        },
        {
          "text": "Machine Learning",
          "rationale": "Machine Learning is a statistical approach, whereas GOFAI is based on logic and rules.",
          "isCorrect": false
        },
        {
          "text": "Symbolic AI",
          "rationale": "This is correct. GOFAI, or Symbolic AI, was the dominant paradigm in early AI research and relied on programming explicit rules and logical reasoning.",
          "isCorrect": true
        },
        {
          "text": "Generative AI",
          "rationale": "Generative AI is a very recent development based on deep learning.",
          "isCorrect": false
        }
      ],
      "hint": "This early approach to AI tried to create intelligence by writing down rules for the computer to follow."
    },
    {
      "questionNumber": 82,
      "question": "The ability of an AI system to understand context, emotions, and nuances in human communication is the focus of which field?",
      "answerOptions": [
        {
          "text": "Computer Vision",
          "rationale": "Computer Vision focuses on interpreting visual information.",
          "isCorrect": false
        },
        {
          "text": "Conversational AI / NLP",
          "rationale": "This is the primary goal of advanced Natural Language Processing and Conversational AImoving beyond literal meaning to understand intent and nuance.",
          "isCorrect": true
        },
        {
          "text": "Robotics",
          "rationale": "Robotics is concerned with physical action and manipulation.",
          "isCorrect": false
        },
        {
          "text": "Autonomous Systems",
          "rationale": "Autonomous systems focus on independent operation, which may or may not involve deep language understanding.",
          "isCorrect": false
        }
      ],
      "hint": "This field aims to make interactions with machines feel more natural and human-like."
    },
    {
      "questionNumber": 83,
      "question": "What is 'environmental justice'?",
      "answerOptions": [
        {
          "text": "The legal framework for punishing polluters.",
          "rationale": "While legal action can be a tool for environmental justice, the term itself has a broader meaning related to fairness.",
          "isCorrect": false
        },
        {
          "text": "Ensuring that environmental benefits and burdens (like pollution) are distributed fairly across all communities.",
          "rationale": "This is the correct definition. It addresses the issue that environmental hazards often disproportionately affect marginalized and low-income communities.",
          "isCorrect": true
        },
        {
          "text": "The scientific study of justice systems in different ecosystems.",
          "rationale": "This is an incorrect, literal interpretation of the words.",
          "isCorrect": false
        },
        {
          "text": "A movement to give legal rights to natural entities like rivers and forests.",
          "rationale": "This is part of a broader environmental movement but is not the specific definition of environmental justice.",
          "isCorrect": false
        }
      ],
      "hint": "This concept combines principles of fairness and social justice with environmental issues."
    },
    {
      "questionNumber": 84,
      "question": "One of the twenty recommendations for a 'Good AI Society' is to:",
      "answerOptions": [
        {
          "text": "Halt all AI research until it is proven to be 100% safe.",
          "rationale": "The recommendations focus on responsible development and governance, not a complete halt.",
          "isCorrect": false
        },
        {
          "text": "Create a European observatory for AI to monitor developments.",
          "rationale": "The materials explicitly list 'Create a European observatory for AI' as one of the twenty recommendations under the 'Developments' category.",
          "isCorrect": true
        },
        {
          "text": "Keep AI development exclusively within private companies.",
          "rationale": "The recommendations call for collaboration between government, industry, and academia, not exclusivity.",
          "isCorrect": false
        },
        {
          "text": "Avoid all regulations to encourage maximum innovation.",
          "rationale": "The recommendations call for robust regulations and ethical oversight, not a lack of them.",
          "isCorrect": false
        }
      ],
      "hint": "This recommendation falls under the category of 'Developments' and involves monitoring and supervision at a continental level."
    },
    {
      "questionNumber": 85,
      "question": "true or false: Human decision-making is superior to AI decision-making in all situations because it includes intuition and emotions.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "AI excels in specific, data-intensive domains where it can be more consistent and accurate than humans.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "The materials highlight that while human decision-making is flexible and includes ethical considerations, AI excels in specific domains (like chess or medical image analysis) by relying on vast data and consistent algorithms.",
          "isCorrect": true
        }
      ],
      "hint": "Consider tasks that involve processing huge amounts of data without bias, like analyzing thousands of medical scans."
    },
    {
      "questionNumber": 86,
      "question": "Which of these is NOT a key component of 'Digital Ethics'?",
      "answerOptions": [
        {
          "text": "Privacy",
          "rationale": "Protecting individuals' personal data is listed as a key aspect of digital ethics.",
          "isCorrect": false
        },
        {
          "text": "Fairness",
          "rationale": "Avoiding biases in AI and digital systems is a core component.",
          "isCorrect": false
        },
        {
          "text": "Profitability",
          "rationale": "Profitability is a business goal, not a core moral principle of digital ethics.",
          "isCorrect": true
        },
        {
          "text": "Accountability",
          "rationale": "Holding developers and organizations responsible for the outcomes of their technologies is a key aspect.",
          "isCorrect": false
        }
      ],
      "hint": "Look for the option that is a business objective rather than a moral principle."
    },
    {
      "questionNumber": 87,
      "question": "The 'Stanford Cart', one of the initial autonomous vehicles, was developed in which decade?",
      "answerOptions": [
        {
          "text": "1960s",
          "rationale": "The 1960s saw early chatbots and industrial robots.",
          "isCorrect": false
        },
        {
          "text": "1970s",
          "rationale": "The timeline in the materials places the Stanford Cart's development in 1979.",
          "isCorrect": true
        },
        {
          "text": "1980s",
          "rationale": "The 1980s saw Mercedes-Benz develop a driverless car, but the Stanford Cart was an earlier university project.",
          "isCorrect": false
        },
        {
          "text": "1990s",
          "rationale": "The 1990s was when AI research saw a resurgence with machine learning.",
          "isCorrect": false
        }
      ],
      "hint": "This early autonomous vehicle was developed during the first AI Winter."
    },
    {
      "questionNumber": 88,
      "question": "What is a primary social implication of the increasing use of AI in manufacturing and retail?",
      "answerOptions": [
        {
          "text": "An increase in product quality.",
          "rationale": "While this is a benefit, the question asks for a social implication.",
          "isCorrect": false
        },
        {
          "text": "The impact on employment and potential job displacement.",
          "rationale": "The materials repeatedly highlight job displacement as a major social implication of automation through AI in industries like manufacturing, retail, and finance.",
          "isCorrect": true
        },
        {
          "text": "A decrease in the price of consumer goods.",
          "rationale": "This is a potential economic impact, but job displacement is a more direct and widely discussed social implication.",
          "isCorrect": false
        },
        {
          "text": "An increase in data privacy.",
          "rationale": "The use of AI in retail often leads to more data collection, raising privacy concerns rather than increasing privacy.",
          "isCorrect": false
        }
      ],
      "hint": "Consider how automation affects the human workforce."
    },
    {
      "questionNumber": 89,
      "question": "The ability of AI to identify individuals using physical characteristics like their face or fingerprints is known as:",
      "answerOptions": [
        {
          "text": "Robotics",
          "rationale": "Robotics involves physical machines.",
          "isCorrect": false
        },
        {
          "text": "Biometrics",
          "rationale": "Biometrics is the technology that uses unique physical or behavioral characteristics for identification and access control.",
          "isCorrect": true
        },
        {
          "text": "Natural Language Generation",
          "rationale": "This involves creating text from data.",
          "isCorrect": false
        },
        {
          "text": "Deep Learning",
          "rationale": "Deep learning is the technique often used to achieve biometric recognition, but biometrics is the name of the application.",
          "isCorrect": false
        }
      ],
      "hint": "This technology is often used for unlocking smartphones and for security systems."
    },
    {
      "questionNumber": 90,
      "question": "true or false: The principle of 'receiver-contextualized intervention' in AI for Social Good means that a single, universal AI solution should be applied to everyone to ensure fairness.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The principle advocates for tailoring interventions to the specific context of the user, not applying a universal solution.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "This principle emphasizes that AI interventions should be sensitive to the user's specific needs, circumstances, and environment to be appropriate and beneficial.",
          "isCorrect": true
        }
      ],
      "hint": "Does 'contextualized' suggest a universal approach or a tailored one?"
    },
    {
      "questionNumber": 91,
      "question": "What is the primary purpose of an 'ethical audit' for an AI system?",
      "answerOptions": [
        {
          "text": "To improve the model's predictive accuracy.",
          "rationale": "Improving accuracy is a technical goal; an ethical audit focuses on compliance with ethical principles.",
          "isCorrect": false
        },
        {
          "text": "To assess compliance with ethical principles and identify areas for improvement.",
          "rationale": "This is the correct definition. Ethical audits check for issues like bias, lack of transparency, and unfairness, ensuring the system aligns with ethical guidelines.",
          "isCorrect": true
        },
        {
          "text": "To calculate the financial return on investment of the AI.",
          "rationale": "This is a financial audit, not an ethical one.",
          "isCorrect": false
        },
        {
          "text": "To secure the system against cyberattacks.",
          "rationale": "This would be a security audit, which is related but distinct from an ethical audit.",
          "isCorrect": false
        }
      ],
      "hint": "Think about what an audit is designed to check for, but in the context of ethics."
    },
    {
      "questionNumber": 92,
      "question": "Which of these is a key difference in decision-making between humans and current AI?",
      "answerOptions": [
        {
          "text": "AI can make decisions, but humans cannot.",
          "rationale": "Humans make decisions constantly.",
          "isCorrect": false
        },
        {
          "text": "Humans use intuition, experience, and emotions, while AI relies on data and algorithms.",
          "rationale": "This is the fundamental difference highlighted in the materials. Human decision-making is holistic, while AI's is data-driven and logical.",
          "isCorrect": true
        },
        {
          "text": "AI is always more accurate than humans.",
          "rationale": "AI can be more accurate in specific domains, but humans are more flexible and can handle ambiguity better in many situations.",
          "isCorrect": false
        },
        {
          "text": "Humans make decisions slowly, while AI is always fast.",
          "rationale": "While generally true, the core difference is in the process and inputs, not just the speed.",
          "isCorrect": false
        }
      ],
      "hint": "Consider the different types of inputs that go into a decision for a person versus a computer."
    },
    {
      "questionNumber": 93,
      "question": "The development of 'ethical codes of conduct' for AI professionals is an example of which type of ethical framework?",
      "answerOptions": [
        {
          "text": "Hard Ethics",
          "rationale": "Hard ethics refers to legally binding laws.",
          "isCorrect": false
        },
        {
          "text": "Soft Ethics",
          "rationale": "Codes of conduct are a prime example of soft ethics, as they are voluntary, non-binding guidelines that encourage ethical behavior.",
          "isCorrect": true
        },
        {
          "text": "Digital Regulation",
          "rationale": "Digital regulation involves government-enforced laws, not professional codes of conduct.",
          "isCorrect": false
        },
        {
          "text": "Digital Governance",
          "rationale": "Digital governance is the internal management framework of an organization.",
          "isCorrect": false
        }
      ],
      "hint": "Are these codes of conduct legally enforceable or are they guidelines for professionals?"
    },
    {
      "questionNumber": 94,
      "question": "true or false: A major ethical concern with AI is that it can inherit and amplify biases present in the data it is trained on.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "This is a central and frequently mentioned ethical challenge. If historical data reflects societal biases, the AI will learn and potentially exacerbate them.",
          "isCorrect": true
        },
        {
          "text": "false",
          "rationale": "This is one of the most significant and widely discussed ethical problems in AI today.",
          "isCorrect": false
        }
      ],
      "hint": "If an AI is trained on past hiring decisions that were biased, what will the AI learn to do?"
    },
    {
      "questionNumber": 95,
      "question": "Using AI-driven social media bots to spread false information during an election is a misuse of AI that primarily threatens:",
      "answerOptions": [
        {
          "text": "Economic stability",
          "rationale": "While it could have economic effects, the primary target is the political process.",
          "isCorrect": false
        },
        {
          "text": "National security",
          "rationale": "It could be a national security threat, but its most direct impact is on the democratic process.",
          "isCorrect": false
        },
        {
          "text": "Public opinion and democracy",
          "rationale": "The materials specifically list 'Manipulation of Public Opinion and Democracy' as a form of social evil, where AI is used to influence voter behavior and alter election outcomes.",
          "isCorrect": true
        },
        {
          "text": "Individual privacy",
          "rationale": "While data might be used to target propaganda, the main goal and harm is the manipulation of the democratic process.",
          "isCorrect": false
        }
      ],
      "hint": "This type of misuse targets the integrity of the political process."
    },
    {
      "questionNumber": 96,
      "question": "Which one of these is NOT a branch of AI research mentioned in the materials?",
      "answerOptions": [
        {
          "text": "Machine learning",
          "rationale": "Machine learning is a core branch of AI.",
          "isCorrect": false
        },
        {
          "text": "Natural language processing",
          "rationale": "NLP is a major branch of AI research.",
          "isCorrect": false
        },
        {
          "text": "Quantum mechanics",
          "rationale": "While quantum computing can be used for AI, quantum mechanics itself is a field of physics, not a branch of AI research.",
          "isCorrect": true
        },
        {
          "text": "Computer vision",
          "rationale": "Computer vision is a significant branch of AI research.",
          "isCorrect": false
        }
      ],
      "hint": "Look for the option that is a fundamental field of physics."
    },
    {
      "questionNumber": 97,
      "question": "The ability of an AI to adapt and improve its performance over time by learning from new data and experiences is called:",
      "answerOptions": [
        {
          "text": "Autonomy",
          "rationale": "Autonomy is the ability to operate without human intervention.",
          "isCorrect": false
        },
        {
          "text": "Adaptability",
          "rationale": "This is the correct term for the capacity to learn and improve performance based on new information or experiences.",
          "isCorrect": true
        },
        {
          "text": "Agency",
          "rationale": "Agency is the broader capacity to act independently, of which adaptability is a key component.",
          "isCorrect": false
        },
        {
          "text": "Creativity",
          "rationale": "Creativity is the ability to generate new ideas, not just improve performance on a task.",
          "isCorrect": false
        }
      ],
      "hint": "This quality allows an AI to get better at its job over time."
    },
    {
      "questionNumber": 98,
      "question": "What is the primary motivation for developing Explainable AI (XAI)?",
      "answerOptions": [
        {
          "text": "To make AI models run faster on less powerful hardware.",
          "rationale": "This is the goal of efficiency-focused AI research (like Green AI), not XAI.",
          "isCorrect": false
        },
        {
          "text": "To build trust and address ethical challenges by making AI systems more transparent and accountable.",
          "rationale": "This is the core purpose of XAI. By understanding why an AI made a certain decision, we can trust it more, hold it accountable, and ensure it is fair.",
          "isCorrect": true
        },
        {
          "text": "To allow AI to generate more creative and original content.",
          "rationale": "This is the goal of Generative AI.",
          "isCorrect": false
        },
        {
          "text": "To enable AI systems to interact with the physical world.",
          "rationale": "This is the domain of Robotics and Autonomous Systems.",
          "isCorrect": false
        }
      ],
      "hint": "This field of AI seeks to solve the 'black box' problem."
    },
    {
      "questionNumber": 99,
      "question": "true or false: The digital revolution hindered the development of AI by making data too complex to analyze.",
      "answerOptions": [
        {
          "text": "true",
          "rationale": "The digital revolution was the primary catalyst for modern AI.",
          "isCorrect": false
        },
        {
          "text": "false",
          "rationale": "The digital revolution was instrumental in the emergence of modern AI by providing the necessary hardware (powerful processors like GPUs), software infrastructure, and vast amounts of 'big data' needed to train complex models.",
          "isCorrect": true
        }
      ],
      "hint": "Think about whether modern AI would be possible without powerful computers and the internet."
    },
    {
      "questionNumber": 100,
      "question": "If a company uses an AI system to analyze customer data for marketing but fails to get proper consent from users, it is primarily violating which two ethical principles?",
      "answerOptions": [
        {
          "text": "Beneficence and Justice",
          "rationale": "While the use might not be beneficial or just, the core violation relates to consent and potential harm from data misuse.",
          "isCorrect": false
        },
        {
          "text": "Nonmaleficence and Autonomy",
          "rationale": "This is the best answer. It violates Nonmaleficence by creating the potential for harm through a privacy breach. It violates Autonomy by not respecting the users' right to make an informed choice (consent) about how their data is used.",
          "isCorrect": true
        },
        {
          "text": "Justice and Explicability",
          "rationale": "While the system may not be just or explicable, the primary issue described is the lack of user consent and privacy protection.",
          "isCorrect": false
        },
        {
          "text": "Explicability and Beneficence",
          "rationale": "The problem is not about whether the system is understandable or beneficial, but about the user's rights and the potential for harm.",
          "isCorrect": false
        }
      ],
      "hint": "Which principle relates to avoiding harm (like a privacy breach), and which relates to respecting a person's right to choose?"
    }
  ]
}